{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation based on the matlab code by M. Rabbat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle, random\n",
    "from scipy.special import gamma as gamma_function\n",
    "from scipy.special import comb\n",
    "from scipy.sparse import csr_matrix\n",
    "import itertools\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 #number of nodes in the network\n",
    "T = 100 #number of paths\n",
    "Nm = 5 #number of nodes per path\n",
    "# np.random.seed(2)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(n, n)\n",
    "A = A / A.sum(axis = 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.random.rand(n, 1)\n",
    "pi = pi / pi.sum(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some paths according to this Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((T, Nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random numbers for testing purposes. Change to random() when it is ready\n",
    "R_out = np.random.rand(T,1)\n",
    "R_in = np.random.rand(T, Nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumprobs = pi.cumsum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "for walk in X:\n",
    "#     Sample the starting node from Pi\n",
    "#     larger = (cumprobs >= random()).nonzero()\n",
    "    larger = (cumprobs >= R_out[iterator][0]).nonzero()\n",
    "    walk[0] = larger[0][0]\n",
    "#     Sample remaining nodes in the path by taking a random walk\n",
    "    for i in range(1, Nm):\n",
    "        cumprobs_in = A[int(walk[i - 1]),:].cumsum(axis=0)\n",
    "#       larger = (cumprobs >= random()).nonzero()\n",
    "        larger = (cumprobs_in >= R_in[iterator][i]).nonzero()\n",
    "        walk[i] = larger[0][0]\n",
    "    iterator += 1\n",
    "X = X.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = X.copy()\n",
    "# for walk in Y:\n",
    "#     shuffle(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numTrials = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_csr_rows(csr_mat):\n",
    "    row_sums = np.array(csr_mat.sum(axis=1))[:,0]\n",
    "    row_indices, col_indices = csr_mat.nonzero()\n",
    "    csr_mat.data /= row_sums[row_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_csr_columns(csr_mat):\n",
    "    col_sums = np.array(csr_mat.sum(axis=0))[0,:]\n",
    "    row_indices, col_indices = csr_mat.nonzero()\n",
    "    csr_mat.data /= col_sums[col_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_probabilities(bag_of_nodes, pi_hat, A_hat, full_probs = True):\n",
    "    n = len(bag_of_nodes)\n",
    "    \n",
    "    permutation_orders = list(itertools.permutations(list(range(n))))\n",
    "    \n",
    "    gamma = np.zeros(n)\n",
    "    Gamma = np.zeros((n,n))\n",
    "    probability = 0\n",
    "    \n",
    "    for order in permutation_orders:\n",
    "        starting_node = order[0]\n",
    "        p = pi_hat[bag_of_nodes[starting_node]]\n",
    "        \n",
    "        for i in range(1, n):\n",
    "            p = p * A_hat[bag_of_nodes[order[i - 1]], bag_of_nodes[order[i]]]\n",
    "        \n",
    "        if full_probs:\n",
    "            gamma[order[0]] += p\n",
    "        \n",
    "            for i in range(1, n):\n",
    "                Gamma[order[i - 1]][order[i]] += p\n",
    "        else:\n",
    "            probability += p\n",
    "    \n",
    "    if full_probs:\n",
    "        return gamma, Gamma\n",
    "    else:\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik(X, A, pi):\n",
    "    ll = 0\n",
    "    for walk in X:\n",
    "        l = len(walk)\n",
    "        p = 0\n",
    "        for i in range(l):\n",
    "            p = permutation_probabilities(walk, pi, A, full_probs=False)\n",
    "        ll += log(p) - log(gamma_function(l + 1))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def overlapped_chunks(array, chunk_size = 2, overlap_size = 1):\n",
    "#     return [tuple(array[i:i+chunk_size]) for i in range(0, len(array)-1, chunk_size-overlap_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NICO implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TBD Change names. Come up with something meaningful and readable\n",
    "\n",
    "def nico(X, n):\n",
    "#     T = np.shape(X)[0]\n",
    "    \n",
    "    #number of nodes in each path\n",
    "#     size = lambda array: len(array)\n",
    "#     Nm = np.apply_along_axis(size, 1, X)\n",
    "    \n",
    "    #Init pi_hat\n",
    "    #Assume all states appear at least once in the data\n",
    "    pi_hat = 1 + 0.3 * np.random.rand(n, 1)\n",
    "    pi_hat = pi_hat / pi_hat.sum(axis = 0, keepdims = True)\n",
    "    pi_hat = [item[0] for item in pi_hat]\n",
    "    \n",
    "    # Construct A_hat as a sparse matrix\n",
    "    # First determine an upperbound on the number of non-zero entries\n",
    "    ii = []\n",
    "    jj = []\n",
    "\n",
    "    for walk in X:\n",
    "        V = np.array(list(itertools.combinations(walk, 2)))\n",
    "        ii.append(list(V[:, 0]))\n",
    "        jj.append(list(V[:, 1]))\n",
    "\n",
    "    ii = [item for sublist in ii for item in sublist]\n",
    "    jj = [item for sublist in jj for item in sublist]\n",
    "    ss = np.ones(len(ii))\n",
    "    \n",
    "    A_hat = csr_matrix((ss, (ii, jj)), shape = (n,n))\n",
    "    A_hat = (A_hat + A_hat.transpose()) / 2\n",
    "    A_hat_copy = A_hat.copy()\n",
    "    A_hat_copy.data.fill(1)\n",
    "    \n",
    "    A_hat = A_hat_copy + 0.4 * csr_matrix((np.random.random((A_hat.nnz)),A_hat.nonzero()), shape=A_hat.shape)\n",
    "    \n",
    "    #Normalize A_hat\n",
    "    normalize_csr_columns(A_hat)\n",
    "    A_hat = A_hat.transpose()\n",
    "    \n",
    "    # EM algorithm\n",
    "    tol = 0.01\n",
    "    kmax = 100\n",
    "    for k in range(kmax):\n",
    "        # E-STEP\n",
    "        #Test on one permutation\n",
    "        r_alpha_gamma = []\n",
    "        r_alpha_Gamma = []\n",
    "\n",
    "        for bag_of_nodes in X:\n",
    "            gamma, Gamma = permutation_probabilities(bag_of_nodes, pi_hat, A_hat)\n",
    "            gamma_sum = sum(gamma)\n",
    "            r_alpha_gamma.append(gamma/gamma_sum)\n",
    "            r_alpha_Gamma.append(Gamma/gamma_sum)\n",
    "\n",
    "        # M-STEP\n",
    "        #1. Sum probabilities for gamma\n",
    "        c = np.zeros(n)\n",
    "        for seq, probs in zip(X, r_alpha_gamma):\n",
    "            for node_id in range(n):\n",
    "                node_indexes = [i for i, j in enumerate(seq) if j == node_id]\n",
    "                c[node_id] += probs[node_indexes].sum()\n",
    "\n",
    "        #2. Sum probabilities for Gamma\n",
    "        C = np.zeros((n,n))\n",
    "        for seq, probs in zip(X, r_alpha_Gamma):\n",
    "            l = len(seq)\n",
    "            for i in range(l - 1):\n",
    "                for j in range(i + 1, l):\n",
    "                    C[(seq[i],seq[j])] += probs[(i,j)]\n",
    "                    C[(seq[j],seq[i])] += probs[(j,i)]\n",
    "\n",
    "        A_hat_old = A_hat.copy()\n",
    "        pi_hat_old = pi_hat.copy()\n",
    "\n",
    "        A_hat = csr_matrix(C)\n",
    "        pi_hat = c\n",
    "\n",
    "        #Normalize\n",
    "        pi_hat = pi_hat / pi_hat.sum(axis = 0, keepdims = True)\n",
    "        normalize_csr_rows(A_hat)\n",
    "\n",
    "        # Compute change in Q\n",
    "        Q = 0\n",
    "        Q_old = 0\n",
    "        for seq, probs in zip(X, r_alpha_gamma):\n",
    "            l = len(seq)\n",
    "            for node_id in range(l):\n",
    "                Q += probs[node_id] * log(pi_hat[seq[node_id]])\n",
    "                Q_old += probs[node_id] * log(pi_hat_old[seq[node_id]])\n",
    "\n",
    "        for seq, probs in zip(X, r_alpha_Gamma):\n",
    "            l = len(seq)\n",
    "            for i in range(l - 1):\n",
    "                for j in range(i + 1, l):\n",
    "                    Q += probs[(i,j)] * log(A_hat[(seq[i], seq[j])] + np.finfo(float).eps)\n",
    "                    Q += probs[(j,i)] * log(A_hat[(seq[j], seq[i])] + np.finfo(float).eps)\n",
    "\n",
    "                    Q_old += probs[(i,j)] * log(A_hat_old[(seq[i], seq[j])] + np.finfo(float).eps)\n",
    "                    Q_old += probs[(j,i)] * log(A_hat_old[(seq[j], seq[i])] + np.finfo(float).eps)\n",
    "\n",
    "        delta = Q - Q_old\n",
    "\n",
    "        # Check stopping criterion\n",
    "        sc = delta / tol\n",
    "        \n",
    "        print(\"Iter: {0} || Delta: {1:.2f} || Q: {2:.2f}\".format(k + 1, delta, Q))\n",
    "        \n",
    "        if sc < 1:\n",
    "            print(\"Terminated successfully after {0} iterations.\".format(k + 1))\n",
    "            break\n",
    "            \n",
    "        if k == kmax - 1:\n",
    "            print(\"Number of EM iterations exceeded the limit.\")\n",
    "    \n",
    "    return pi_hat, A_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pi_hat, A_hat = nico(X, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NICO trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 50\n",
    "ll = []\n",
    "l1 = []\n",
    "for i in range(num_trials):\n",
    "    print(\"Trial {0}:\".format(i + 1))\n",
    "    pi_hat, A_hat = nico(X, n)\n",
    "    ll.append(loglik(X, A_hat, pi_hat))\n",
    "    l1.append(np.sum(np.abs(A_hat - A)) + np.sum(np.abs(pi_hat - pi.flatten())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
